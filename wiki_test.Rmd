---
title: "Wikipedia History Proof of Concept"
author: "Adam Campbell"
date: "25/11/2020"
output: html_document
---

The goal of this script is to download data from wikipedia on the complete edit history of an article.  Eventually I might like to turn this into a R package, but for the time being I'll keep this as a markdown file for a proof of concept.

To do this work I made use [Wikipedia's API Tool](https://www.mediawiki.org/wiki/API:Revisions#Example_2:_Get_last_five_revisions_of_a_page_filtered_by_date_and_user) and [Dataquest's API tool](https://www.dataquest.io/blog/r-api-tutorial/)

If I ever do make this into a package, I'll try to follow [these interesting instruction ](https://tinyheero.github.io/jekyll/update/2015/07/26/making-your-first-R-package.html)

First load the libraries for doing the query.
```{r message=FALSE, load-libraries}
library(httr)
library(jsonlite)
library(tidyverse)
library(lubridate)
```

Here are two functions, `get_500_recent` will get the 500 (Wikipedia's limit) of most recent edits on the page,  `get_500_recent` get's the full edit history.   
```{r}
# get 500 results

get_500_recent <- function(title, start_date = "start"){
  base_list = list(
    action = "query", 
    prop = "revisions",
    rvprop = "timestamp",
    rvlimit = "500",
    rvslots = "main",
    formatversion = "2",
    rvdir = "newer",
    format = "json"
  )
  
  # make list
  if (start_date == "start") {
    supp_list = list(
      titles = title
    )  
  } else {
    supp_list = list(
      titles = title,
      rvstart = start_date
    )
  }

  query_list = c(base_list, supp_list)
  
  res = GET(
    "http://en.wikipedia.org/w/api.php", 
    query = query_list
    )

  data = fromJSON(rawToChar(res$content))
  
  dom <- data$query$pages$revisions[[1]]
  
  return(dom)
}

# get full edit history

get_edit_history <- function(title){
  
  first_data <- get_500_recent(title)
  
  if (nrow(first_data) < 500 ) {
    return(first_data)
  } 
  
  fetched_data <- first_data
  data_out <- fetched_data
  
  while (nrow(fetched_data) == 500 ){
    data_out <- data_out %>% filter(row_number() <= n()-1)
    date_start <- as.character(tail(fetched_data, n=1))
    fetched_data <- get_500_recent(title, date_start)
    data_out <- rbind(data_out, fetched_data)
  }
  return(data_out)
}
```

Let's do a test for "Coronavirus disease 2019"
```{r}
title = "Coronavirus_disease_2019"
my_data <- get_edit_history(title)
```

Have to formulate the dates
```{r}
my_data$dates <- as_date(my_data$timestamp)
my_data$testdatetime <- parse_date_time(my_data$timestamp,"y m d HMS")
my_data$testmonth <- month(my_data$timestamp)
```

And do a simple plot of the results
```{r}
ggplot(my_data) + aes(x = lubridate::floor_date(dates, "month")) + 
  geom_bar() +
  theme_minimal()
```

This bar graph is informative but what I want is for each day have a count of the edits and another plot on top that is a running average.

```{r}
library(zoo)

ggplot(my_data %>% count(dates), aes(x = dates, n)) +
  geom_point(alpha = 0.1, color='darkblue') +
  geom_line(aes(y=rollmean(n, 14, na.pad=TRUE)), color="purple", size =1.5) +
  labs(y = "edit count") +
  ylim(0,100) +
  theme_minimal() + 
  theme(axis.title.x = element_blank())
```

So I'm pretty happy with that.  I want to now explore 2020 VP picks.

```{r}
Harris_data <- get_edit_history("Kamala_Harris")
Rice_data <- get_edit_history("Susan_Rice")
Warren_data <- get_edit_history("Elizabeth_Warren")
Whitmer_data <- get_edit_history("Gretchen_Whitmer")
Duckworth_data <- get_edit_history("Tammy_Duckworth")
Abrams_data <- get_edit_history("Stacey_Abrams")
```

Make the dates nice
```{r}
Harris_data$dates <- as_date(Harris_data$timestamp)
Rice_data$dates <- as_date(Rice_data$timestamp)
Warren_data$dates <- as_date(Warren_data$timestamp)
Whitmer_data$dates <- as_date(Whitmer_data$timestamp)
Duckworth_data$dates <- as_date(Duckworth_data$timestamp)
Abrams_data$dates <- as_date(Abrams_data$timestamp)
```



```{r}
ggplot(Harris_data %>% count(dates), aes(x = dates, n)) +
  geom_point(alpha = 0.1, color='darkblue') +
  geom_line(aes(y=rollmean(n, 14, na.pad=TRUE)), color="purple", size =1.5) +
  labs(y = "edit count") +
  lims(x = as.Date(c("2016-01-01", "2020-01-01")), y = c(0,50))+
  theme_minimal() + 
  theme(axis.title.x = element_blank())


```

```{r}
Harris_data$pick <- "Harris" 
Rice_data$pick <- "Rice"
Warren_data$pick <- "Warren"
Whitmer_data$pick <- "Whitmer"
Duckworth_data$pick <- "Duckworth"
Abrams_data$pick <- "Abrams"
```

```{r}

VP_data <- rbind(Harris_data,Rice_data,Warren_data, Whitmer_data, Duckworth_data, Abrams_data)
```


Do the initial count of dates
```{r}
VP_data_dates <- VP_data %>%
  group_by(pick) %>%
  count(dates)
```

fill in zeros for uncounted days
```{r}
earliest_date <- min(VP_data_dates$dates)
latest_date <- max(VP_data_dates$dates)
date_range <- seq(earliest_date, latest_date, "days")

VP_data_dates <- VP_data_dates %>%
  group_by(pick) %>%
  complete(dates = date_range) %>%
  mutate(n = replace_na(n,0))
```



Key dates 
march 15 - biden promises a woman
april 08 - Biden become presumptive nominee
april 30 - vetting committee announced
aug 11 - selection of Harris

```{r}
keydate_dates <- as.Date(c("2020-03-15", "2020-04-08", "2020-04-30", "2020-08-11"))
keydate_events <- c("Biden promises to nominate a woman", "Biden become presumptive nominee", "VP Vetting committee anounced", "Harris annouced as VP pick")
keydate_key <- c(1,2,3,4)
keydates <- data.frame(keydate_dates, keydate_events, keydate_key)
```



```{r}
library(scales)
library(ggrepel)
ggplot(VP_data_dates, aes(x = dates, y = n, color = pick)) +
  geom_vline( xintercept = keydates$keydate_dates, linetype = "dashed") +

  geom_point( alpha = 0.2) +
  geom_line(aes(y=rollmean(n, 7, na.pad=TRUE, align = "center")), size =1.2) +
  labs(y = "edit count") +
  lims(x = as.Date(c("2020-01-01", "2020-09-01")), y = c(0,100))+
  scale_x_date(date_breaks = "months" , date_labels = "%b", limits = as.Date(c("2020-01-01", "2020-09-01"))) +
  theme_minimal() +
  theme(axis.title.x = element_blank())
```
```{r}

ggplot() +
  geom_vline(xintercept = keydates$keydate_dates, linetype = "dashed", color = "darkgrey") +
  geom_point(data = VP_data_dates, aes(x = dates, y = n, color = pick), alpha = 0.2) +
  geom_line(aes(x = dates,y=rollmean(n, 7, na.pad=TRUE, align = "center"), color = pick), size =1.2, data = VP_data_dates) +
  geom_text(mapping = aes(x = keydate_dates,
                        y = -1,
                        label = keydate_key,
                        angle = 0,
                        hjust = 0,
                        vjust = 1
                        ),
          data = keydates) +
  labs(y = "edit count") +
  labs(color = "potential VP pick") +
  lims(x = as.Date(c("2020-01-01", "2020-09-01")), y = c(-1,100))+
  scale_x_date(date_breaks = "months" , date_labels = "%b", limits = as.Date(c("2020-01-01", "2020-09-01"))) +
  theme_minimal() +
  theme(axis.title.x = element_blank())
```

Ideas
add lables to timeline
clean up graph
Sum of edits
Cummulative edits

```{r}
VP_data_dates_cum <- VP_data_dates %>%
  filter(dates >= as.Date("2020-01-01")) %>%
  group_by(pick) %>%
  mutate(cum_n = cumsum(n))

```


make cumsum plot
```{r}

ggplot() +
  geom_vline(xintercept = keydates$keydate_dates, linetype = "dashed", color = "darkgrey") +
  geom_line(aes(x = dates,y=cum_n, color = pick), size =1.2, data = VP_data_dates_cum) +
  geom_text(mapping = aes(x = keydate_dates,
                        y = -1,
                        label = keydate_key,
                        angle = 0,
                        hjust = 0,
                        vjust = 1
                        ),
          data = keydates,
          nudge_x = 2,
          nudge_y = -2,
          size = 3) +
  labs(y = "cummulative edit count from 01-Jan-2020") +
  labs(color = "potential VP pick") +
  lims(x = as.Date(c("2020-01-01", "2020-09-01")), y = c(-10,2000))+
  scale_x_date(date_breaks = "months" , date_labels = "%b", limits = as.Date(c("2020-01-01", "2020-09-01"))) +
  theme_minimal() +
  theme(axis.title.x = element_blank())
```



